#!/usr/bin/env python3
"""
å®Œæ•´ MLOps æµæ°´ç·šè‡ªå‹•åŒ–è…³æœ¬
åŸ·è¡Œå¾è¨“ç·´åˆ°éƒ¨ç½²çš„å®Œæ•´æµç¨‹
"""

import sys
import os
import subprocess
import json
import time
from pathlib import Path
from datetime import datetime
import argparse

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

class MLOpsPipeline:
    """MLOps å…¨æµç¨‹è‡ªå‹•åŒ–"""

    def __init__(self, config_path=None, dry_run=False):
        self.project_root = project_root
        self.dry_run = dry_run
        self.config = self.load_config(config_path)
        self.pipeline_results = {
            "pipeline_start": datetime.now().isoformat(),
            "steps": {}
        }

    def load_config(self, config_path):
        """è¼‰å…¥æµæ°´ç·šé…ç½®"""
        default_config = {
            "training": {
                "config_file": "application/training/configs/iris_config.json",
                "accuracy_threshold": 0.9,
                "performance_threshold_ms": 100
            },
            "validation": {
                "run_validation": True,
                "accuracy_threshold": 0.95
            },
            "service": {
                "build_service": True,
                "run_tests": True,
                "port": 3000
            },
            "deployment": {
                "environment": "staging",
                "auto_deploy": False
            },
            "monitoring": {
                "enable_metrics": True,
                "metrics_port": 8001
            }
        }

        if config_path and Path(config_path).exists():
            with open(config_path, 'r') as f:
                user_config = json.load(f)
            # åˆä½µé…ç½®
            for section in default_config:
                if section in user_config:
                    default_config[section].update(user_config[section])

        return default_config

    def run_command(self, command, cwd=None, description=""):
        """åŸ·è¡Œå‘½ä»¤ä¸¦è¨˜éŒ„çµæœ"""
        if cwd is None:
            cwd = self.project_root

        print(f"ğŸ”§ {description}")
        print(f"åŸ·è¡Œ: {command}")

        if self.dry_run:
            print("(ä¹¾è·‘æ¨¡å¼ - æœªå¯¦éš›åŸ·è¡Œ)")
            return True, "", ""

        try:
            result = subprocess.run(
                command,
                shell=True,
                cwd=cwd,
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†é˜è¶…æ™‚
            )

            if result.returncode == 0:
                print("âœ… æˆåŠŸ")
                return True, result.stdout, result.stderr
            else:
                print(f"âŒ å¤±æ•— (é€€å‡ºç¢¼: {result.returncode})")
                print(f"éŒ¯èª¤è¼¸å‡º: {result.stderr}")
                return False, result.stdout, result.stderr

        except subprocess.TimeoutExpired:
            print("âŒ å‘½ä»¤åŸ·è¡Œè¶…æ™‚")
            return False, "", "å‘½ä»¤åŸ·è¡Œè¶…æ™‚"
        except Exception as e:
            print(f"âŒ åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
            return False, "", str(e)

    def step_1_model_training(self):
        """æ­¥é©Ÿ 1: æ¨¡å‹è¨“ç·´"""
        print("\n" + "="*60)
        print("ğŸ“Š æ­¥é©Ÿ 1: æ¨¡å‹è¨“ç·´")
        print("="*60)

        config_file = self.config["training"]["config_file"]
        command = f"poetry run python application/training/pipelines/iris_training_pipeline.py --config {config_file}"

        success, stdout, stderr = self.run_command(
            command,
            description="è¨“ç·´ Iris åˆ†é¡æ¨¡å‹"
        )

        self.pipeline_results["steps"]["training"] = {
            "success": success,
            "timestamp": datetime.now().isoformat(),
            "stdout": stdout,
            "stderr": stderr
        }

        return success

    def step_2_model_validation(self):
        """æ­¥é©Ÿ 2: æ¨¡å‹é©—è­‰"""
        print("\n" + "="*60)
        print("ğŸ¯ æ­¥é©Ÿ 2: æ¨¡å‹é©—è­‰")
        print("="*60)

        if not self.config["validation"]["run_validation"]:
            print("â­ï¸ è·³éæ¨¡å‹é©—è­‰")
            return True

        threshold = self.config["validation"]["accuracy_threshold"]
        command = f"poetry run python application/validation/model_validation/validate_model.py --model-path application/registry/model_registry/ --threshold {threshold}"

        success, stdout, stderr = self.run_command(
            command,
            description=f"é©—è­‰æ¨¡å‹ (é–¾å€¼: {threshold})"
        )

        self.pipeline_results["steps"]["validation"] = {
            "success": success,
            "timestamp": datetime.now().isoformat(),
            "threshold": threshold,
            "stdout": stdout,
            "stderr": stderr
        }

        return success

    def step_3_build_service(self):
        """æ­¥é©Ÿ 3: å»ºç«‹ BentoML æœå‹™"""
        print("\n" + "="*60)
        print("ğŸš€ æ­¥é©Ÿ 3: å»ºç«‹ BentoML æœå‹™")
        print("="*60)

        if not self.config["service"]["build_service"]:
            print("â­ï¸ è·³éæœå‹™å»ºç«‹")
            return True

        # å…ˆç¢ºä¿æœå‹™æ–‡ä»¶å­˜åœ¨ä¸¦æ›´æ–°
        service_dir = self.project_root / "application" / "inference" / "services"

        # å»ºç«‹ BentoML æœå‹™
        command = "poetry run bentoml build"

        success, stdout, stderr = self.run_command(
            command,
            cwd=service_dir,
            description="å»ºç«‹ BentoML æœå‹™"
        )

        self.pipeline_results["steps"]["build_service"] = {
            "success": success,
            "timestamp": datetime.now().isoformat(),
            "stdout": stdout,
            "stderr": stderr
        }

        return success

    def step_4_test_service(self):
        """æ­¥é©Ÿ 4: æ¸¬è©¦æœå‹™"""
        print("\n" + "="*60)
        print("ğŸ§ª æ­¥é©Ÿ 4: æœå‹™æ¸¬è©¦")
        print("="*60)

        if not self.config["service"]["run_tests"]:
            print("â­ï¸ è·³éæœå‹™æ¸¬è©¦")
            return True

        # å•Ÿå‹•æœå‹™é€²è¡Œæ¸¬è©¦
        service_dir = self.project_root / "application" / "inference" / "services"
        port = self.config["service"]["port"]

        # åœ¨èƒŒæ™¯å•Ÿå‹•æœå‹™
        print("ğŸ”„ å•Ÿå‹•æ¸¬è©¦æœå‹™...")
        if not self.dry_run:
            service_process = subprocess.Popen(
                ["poetry", "run", "bentoml", "serve", "iris_service:IrisClassifier", "--port", str(port)],
                cwd=service_dir,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )

            # ç­‰å¾…æœå‹™å•Ÿå‹•
            time.sleep(10)

            try:
                # é‹è¡ŒåŸºæœ¬æ¸¬è©¦
                test_command = f"poetry run python application/inference/services/test_service.py"
                test_success, test_stdout, test_stderr = self.run_command(
                    test_command,
                    description="åŸ·è¡Œæœå‹™åŠŸèƒ½æ¸¬è©¦"
                )

                if test_success:
                    # é‹è¡Œè² è¼‰æ¸¬è©¦
                    load_test_command = f"poetry run python tests/integration/test_load_performance.py --url http://localhost:{port} --concurrent 5 --requests 10"
                    load_success, load_stdout, load_stderr = self.run_command(
                        load_test_command,
                        description="åŸ·è¡Œæœå‹™è² è¼‰æ¸¬è©¦"
                    )
                else:
                    load_success = False
                    load_stdout = ""
                    load_stderr = "åŠŸèƒ½æ¸¬è©¦å¤±æ•—ï¼Œè·³éè² è¼‰æ¸¬è©¦"

                overall_success = test_success and load_success

            finally:
                # é—œé–‰æœå‹™
                print("ğŸ”„ é—œé–‰æ¸¬è©¦æœå‹™...")
                service_process.terminate()
                service_process.wait(timeout=10)

        else:
            print("(ä¹¾è·‘æ¨¡å¼ - è·³éå¯¦éš›æœå‹™æ¸¬è©¦)")
            overall_success = True
            test_stdout = load_stdout = "ä¹¾è·‘æ¨¡å¼"
            test_stderr = load_stderr = ""

        self.pipeline_results["steps"]["test_service"] = {
            "success": overall_success,
            "timestamp": datetime.now().isoformat(),
            "functional_test": {
                "success": test_success if not self.dry_run else True,
                "stdout": test_stdout,
                "stderr": test_stderr
            },
            "load_test": {
                "success": load_success if not self.dry_run else True,
                "stdout": load_stdout,
                "stderr": load_stderr
            }
        }

        return overall_success

    def step_5_deployment_preparation(self):
        """æ­¥é©Ÿ 5: éƒ¨ç½²æº–å‚™"""
        print("\n" + "="*60)
        print("ğŸ“¦ æ­¥é©Ÿ 5: éƒ¨ç½²æº–å‚™")
        print("="*60)

        environment = self.config["deployment"]["environment"]

        # åŒ¯å‡º BentoML æœå‹™
        service_dir = self.project_root / "application" / "inference" / "services"
        export_command = f"poetry run bentoml export iris_classifier:latest ./iris_service_{environment}.bento"

        success, stdout, stderr = self.run_command(
            export_command,
            cwd=service_dir,
            description=f"åŒ¯å‡ºæœå‹™è‡³ {environment} ç’°å¢ƒ"
        )

        # å‰µå»ºéƒ¨ç½²é…ç½®
        if success and not self.dry_run:
            deployment_config = {
                "environment": environment,
                "service_name": "iris_classifier",
                "export_time": datetime.now().isoformat(),
                "config": self.config["deployment"]
            }

            config_path = service_dir / f"deployment_config_{environment}.json"
            with open(config_path, 'w') as f:
                json.dump(deployment_config, f, indent=2)

        self.pipeline_results["steps"]["deployment_prep"] = {
            "success": success,
            "timestamp": datetime.now().isoformat(),
            "environment": environment,
            "stdout": stdout,
            "stderr": stderr
        }

        return success

    def step_6_deploy(self):
        """æ­¥é©Ÿ 6: è‡ªå‹•éƒ¨ç½² (å¯é¸)"""
        print("\n" + "="*60)
        print("ğŸš€ æ­¥é©Ÿ 6: è‡ªå‹•éƒ¨ç½²")
        print("="*60)

        if not self.config["deployment"]["auto_deploy"]:
            print("â­ï¸ è·³éè‡ªå‹•éƒ¨ç½² (éœ€æ‰‹å‹•éƒ¨ç½²)")
            return True

        environment = self.config["deployment"]["environment"]

        # é€™è£¡å¯ä»¥æ·»åŠ å¯¦éš›çš„éƒ¨ç½²é‚è¼¯
        # ä¾‹å¦‚ï¼šéƒ¨ç½²åˆ° AWS ECS, Google Cloud Run, ç­‰

        print(f"ğŸ”„ éƒ¨ç½²åˆ° {environment} ç’°å¢ƒ...")
        print("ğŸ’¡ æç¤º: åœ¨æ­¤è™•æ·»åŠ æ‚¨çš„éƒ¨ç½²é‚è¼¯")

        # æ¨¡æ“¬éƒ¨ç½²
        if not self.dry_run:
            time.sleep(2)

        self.pipeline_results["steps"]["deployment"] = {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "environment": environment,
            "note": "éƒ¨ç½²é‚è¼¯éœ€è¦æ ¹æ“šå¯¦éš›ç’°å¢ƒé…ç½®"
        }

        return True

    def generate_report(self):
        """ç”Ÿæˆæµæ°´ç·šå ±å‘Š"""
        self.pipeline_results["pipeline_end"] = datetime.now().isoformat()

        # è¨ˆç®—ç¸½é«”æˆåŠŸç‹€æ…‹
        all_steps_success = all(
            step_result.get("success", False)
            for step_result in self.pipeline_results["steps"].values()
        )

        self.pipeline_results["overall_success"] = all_steps_success

        # ä¿å­˜å ±å‘Š
        report_filename = f"mlops_pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_path = self.project_root / "reports" / report_filename
        report_path.parent.mkdir(exist_ok=True)

        with open(report_path, 'w') as f:
            json.dump(self.pipeline_results, f, indent=2, default=str)

        print("\n" + "="*60)
        print("ğŸ“‹ æµæ°´ç·šåŸ·è¡Œç¸½çµ")
        print("="*60)
        print(f"æ•´é«”ç‹€æ…‹: {'âœ… æˆåŠŸ' if all_steps_success else 'âŒ å¤±æ•—'}")
        print(f"å ±å‘Šä½ç½®: {report_path}")

        # é¡¯ç¤ºå„æ­¥é©Ÿç‹€æ…‹
        for step_name, step_result in self.pipeline_results["steps"].items():
            status = "âœ…" if step_result.get("success") else "âŒ"
            print(f"{status} {step_name}")

        return all_steps_success, report_path

    def run_full_pipeline(self):
        """åŸ·è¡Œå®Œæ•´æµæ°´ç·š"""
        print("ğŸš€ é–‹å§‹ MLOps å®Œæ•´æµæ°´ç·š")
        print(f"æ¨¡å¼: {'ä¹¾è·‘' if self.dry_run else 'å¯¦éš›åŸ·è¡Œ'}")
        print("="*60)

        steps = [
            ("æ¨¡å‹è¨“ç·´", self.step_1_model_training),
            ("æ¨¡å‹é©—è­‰", self.step_2_model_validation),
            ("å»ºç«‹æœå‹™", self.step_3_build_service),
            ("æ¸¬è©¦æœå‹™", self.step_4_test_service),
            ("éƒ¨ç½²æº–å‚™", self.step_5_deployment_preparation),
            ("è‡ªå‹•éƒ¨ç½²", self.step_6_deploy)
        ]

        for step_name, step_function in steps:
            try:
                success = step_function()
                if not success:
                    print(f"\nâŒ æµæ°´ç·šåœ¨ '{step_name}' æ­¥é©Ÿå¤±æ•—")
                    if not self.dry_run:
                        break
            except Exception as e:
                print(f"\nâŒ æ­¥é©Ÿ '{step_name}' åŸ·è¡Œæ™‚ç™¼ç”Ÿç•°å¸¸: {str(e)}")
                self.pipeline_results["steps"][step_name.lower().replace(" ", "_")] = {
                    "success": False,
                    "timestamp": datetime.now().isoformat(),
                    "error": str(e)
                }
                if not self.dry_run:
                    break

        # ç”Ÿæˆå ±å‘Š
        overall_success, report_path = self.generate_report()

        if overall_success:
            print(f"\nğŸ‰ MLOps æµæ°´ç·šåŸ·è¡Œå®Œæˆï¼")
        else:
            print(f"\nâš ï¸ MLOps æµæ°´ç·šåŸ·è¡Œé‡åˆ°å•é¡Œï¼Œè«‹æŸ¥çœ‹å ±å‘Š")

        return overall_success

def main():
    parser = argparse.ArgumentParser(description="MLOps å®Œæ•´æµæ°´ç·šè‡ªå‹•åŒ–")
    parser.add_argument("--config", type=str, help="æµæ°´ç·šé…ç½®æ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--dry-run", action="store_true", help="ä¹¾è·‘æ¨¡å¼ (ä¸å¯¦éš›åŸ·è¡Œ)")
    args = parser.parse_args()

    # åŸ·è¡Œæµæ°´ç·š
    pipeline = MLOpsPipeline(config_path=args.config, dry_run=args.dry_run)
    success = pipeline.run_full_pipeline()

    # è¨­ç½®é€€å‡ºç¢¼
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()