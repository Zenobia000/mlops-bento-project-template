import os
import sys
import argparse
import json
from pathlib import Path
from datetime import datetime
import joblib

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

import mlflow
import mlflow.sklearn
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import numpy as np

class IrisTrainingPipeline:
    """Iris åˆ†é¡æ¨¡å‹è¨“ç·´æµæ°´ç·š"""

    def __init__(self, config_path=None):
        self.config = self.load_config(config_path)
        self.setup_mlflow()

    def load_config(self, config_path):
        """è¼‰å…¥è¨“ç·´é…ç½®"""
        default_config = {
            "model": {
                "n_estimators": 100,
                "max_depth": None,
                "random_state": 42
            },
            "data": {
                "test_size": 0.2,
                "random_state": 42
            },
            "experiment_name": "iris_classification_pipeline"
        }

        if config_path and Path(config_path).exists():
            with open(config_path, 'r') as f:
                config = json.load(f)
            # åˆä½µé…ç½®
            for key in default_config:
                if key not in config:
                    config[key] = default_config[key]
            return config

        return default_config

    def setup_mlflow(self):
        """è¨­ç½® MLflow"""
        mlflow.set_experiment(self.config["experiment_name"])

    def load_data(self):
        """è¼‰å…¥å’Œæº–å‚™æ•¸æ“š"""
        print("ğŸ“Š è¼‰å…¥æ•¸æ“š...")
        iris = load_iris()
        X, y = iris.data, iris.target

        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=self.config["data"]["test_size"],
            random_state=self.config["data"]["random_state"],
            stratify=y
        )

        print(f"è¨“ç·´é›†å¤§å°: {X_train.shape}")
        print(f"æ¸¬è©¦é›†å¤§å°: {X_test.shape}")

        return X_train, X_test, y_train, y_test, iris.target_names

    def train_model(self, X_train, y_train):
        """è¨“ç·´æ¨¡å‹"""
        print("ğŸ”§ è¨“ç·´æ¨¡å‹...")
        model = RandomForestClassifier(**self.config["model"])
        model.fit(X_train, y_train)
        return model

    def evaluate_model(self, model, X_test, y_test, target_names):
        """è©•ä¼°æ¨¡å‹"""
        print("ğŸ“ˆ è©•ä¼°æ¨¡å‹...")
        y_pred = model.predict(X_test)

        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)
        cm = confusion_matrix(y_test, y_pred)

        return {
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': cm,
            'predictions': y_pred
        }

    def save_model(self, model, metrics, model_name="iris_classifier"):
        """å„²å­˜æ¨¡å‹å’ŒæŒ‡æ¨™"""
        print("ğŸ’¾ å„²å­˜æ¨¡å‹...")

        # å‰µå»ºæ¨¡å‹ç›®éŒ„
        model_dir = project_root / "application" / "registry" / "model_registry"
        model_dir.mkdir(parents=True, exist_ok=True)

        # å„²å­˜æ¨¡å‹
        model_path = model_dir / f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.joblib"
        joblib.dump(model, model_path)

        # å„²å­˜æŒ‡æ¨™
        metrics_path = model_path.with_suffix('.json')
        with open(metrics_path, 'w') as f:
            # å°‡ numpy æ•¸çµ„è½‰æ›ç‚ºåˆ—è¡¨
            serializable_metrics = {}
            for key, value in metrics.items():
                if isinstance(value, np.ndarray):
                    serializable_metrics[key] = value.tolist()
                else:
                    serializable_metrics[key] = value
            json.dump(serializable_metrics, f, indent=2)

        return str(model_path), str(metrics_path)

    def run_training(self):
        """åŸ·è¡Œå®Œæ•´çš„è¨“ç·´æµæ°´ç·š"""
        print("ğŸš€ é–‹å§‹ MLOps è¨“ç·´æµæ°´ç·š...")

        with mlflow.start_run(run_name=f"iris_pipeline_{datetime.now().strftime('%Y%m%d_%H%M')}"):
            # è¼‰å…¥æ•¸æ“š
            X_train, X_test, y_train, y_test, target_names = self.load_data()

            # è¨˜éŒ„åƒæ•¸
            mlflow.log_params(self.config["model"])
            mlflow.log_params(self.config["data"])

            # è¨“ç·´æ¨¡å‹
            model = self.train_model(X_train, y_train)

            # è©•ä¼°æ¨¡å‹
            metrics = self.evaluate_model(model, X_test, y_test, target_names)

            # è¨˜éŒ„æŒ‡æ¨™
            mlflow.log_metric("accuracy", metrics['accuracy'])
            mlflow.log_metric("precision_macro", metrics['classification_report']['macro avg']['precision'])
            mlflow.log_metric("recall_macro", metrics['classification_report']['macro avg']['recall'])
            mlflow.log_metric("f1_macro", metrics['classification_report']['macro avg']['f1-score'])

            # è¨˜éŒ„æ¨¡å‹åˆ° MLflow
            mlflow.sklearn.log_model(
                sk_model=model,
                artifact_path="model",
                registered_model_name="iris_classifier_pipeline"
            )

            # å„²å­˜æ¨¡å‹åˆ°æœ¬åœ°
            model_path, metrics_path = self.save_model(model, metrics)

            print("âœ… è¨“ç·´å®Œæˆï¼")
            print(f"ğŸ“Š æº–ç¢ºç‡: {metrics['accuracy']:.4f}")
            print(f"ğŸ’¾ æ¨¡å‹å„²å­˜ä½ç½®: {model_path}")
            print(f"ğŸ“ˆ æŒ‡æ¨™å„²å­˜ä½ç½®: {metrics_path}")

            return model, metrics

def main():
    parser = argparse.ArgumentParser(description="Iris åˆ†é¡æ¨¡å‹è¨“ç·´æµæ°´ç·š")
    parser.add_argument("--config", type=str, help="è¨“ç·´é…ç½®æ–‡ä»¶è·¯å¾‘")
    args = parser.parse_args()

    # åŸ·è¡Œè¨“ç·´æµæ°´ç·š
    pipeline = IrisTrainingPipeline(config_path=args.config)
    model, metrics = pipeline.run_training()

    return model, metrics

if __name__ == "__main__":
    main()